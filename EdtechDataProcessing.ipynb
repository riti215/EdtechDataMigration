{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "430781c6-e277-4e1c-95e6-5e821dc943bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, from_json, coalesce, regexp_replace\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "194c147b-98ca-4da5-9eb6-823b7e0e4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Spark session\n",
    "spark = SparkSession.builder.appName(\"EdtechDataProcessingWithHadoop\") \\\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9820\") \\\n",
    "        .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e42eb5f7-dd18-4477-94ca-a47c0f223615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing PostgreSQL connectionn\n",
    "postgres_url = \"jdbc:postgresql://localhost:5432/edtech\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"admin\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68707487-9617-4033-b10c-24fb6b53e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table containing JSON structure column to parse\n",
    "user_registrations = \"user_registrations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05d40231-955b-44f9-824f-0695d02c4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from PostgreSQL\n",
    "df = spark.read.format(\"jdbc\").option(\"url\", postgres_url).option(\"dbtable\", user_registrations).option(\"user\", properties[\"user\"]).option(\"password\", \n",
    "     properties[\"password\"]).option(\"driver\", properties[\"driver\"]).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d040464-ee44-40f0-80c6-9285fbe7e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining schema for JSON data\n",
    "json_schema = StructType([\n",
    "    StructField(\"address\", StructType([\n",
    "        StructField(\"city\", StringType()),\n",
    "        StructField(\"state\", StringType()),\n",
    "        StructField(\"country\", StringType())\n",
    "    ])),\n",
    "    StructField(\"education_info\", StructType([\n",
    "        StructField(\"highest_degree\", StringType()),\n",
    "        StructField(\"cgpa\", StringType())\n",
    "    ])),\n",
    "    StructField(\"profile\", StructType([\n",
    "        StructField(\"gender\", StringType()),\n",
    "        StructField(\"dob\", DateType())\n",
    "    ])),\n",
    "    StructField(\"dob\", DateType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60924e9e-d3cc-44ab-8ebb-38ab10b0d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the JSON structure column\n",
    "df_parsed = df.withColumn(\"user_info_struct\", from_json(col(\"user_info\"), json_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a267a5b7-09ba-40d8-af0b-de6cdc837fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming json structure column into separate individual columns\n",
    "user_registrations_parsed = df_parsed.select(\n",
    "    col(\"user_id\"),\n",
    "    col(\"registration_date\"),\n",
    "    col(\"user_info_struct.address.city\").alias(\"city\"),\n",
    "    col(\"user_info_struct.address.state\").alias(\"state\"),\n",
    "    col(\"user_info_struct.address.country\").alias(\"country\"),\n",
    "    col(\"user_info_struct.education_info.highest_degree\").alias(\"highest_degree\"),\n",
    "    col(\"user_info_struct.education_info.cgpa\").alias(\"cgpa\"),\n",
    "    col(\"user_info_struct.profile.gender\").alias(\"gender\"),\n",
    "    coalesce(col(\"user_info_struct.profile.dob\"), col(\"user_info_struct.dob\")).alias(\"dob\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df0f5f1d-8bb6-4a28-962c-6a4df710132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------------+--------------+-------+--------------+----+------+----------+\n",
      "|    user_id|registration_date|         city|         state|country|highest_degree|cgpa|gender|       dob|\n",
      "+-----------+-----------------+-------------+--------------+-------+--------------+----+------+----------+\n",
      "|CCBP1001USR|       2021-12-12|Visakhapatnam|Andhra Pradesh|  India|        B.Tech| 7.2|  male|1997-01-01|\n",
      "|CCBP1002USR|       2021-01-11|     KAKINADA|Andhra Pradesh|  India|          10th| 8.2|  male|2001-01-01|\n",
      "|CCBP1003USR|       2021-02-11|Visakhapatnam|Andhra Pradesh|  India|        Degree| 7.2|female|1997-10-01|\n",
      "|CCBP1004USR|       2021-12-11|    Hyderabad|     Telangana|  India|          10th| 8.2|female|2002-10-01|\n",
      "|CCBP1007USR|       2021-01-10|      Kurnool|Andhra Pradesh|  India|          10th| 8.2|  male|1998-01-01|\n",
      "+-----------+-----------------+-------------+--------------+-------+--------------+----+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the resulting DataFrame\n",
    "user_registrations_parsed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be82289-8028-448b-9b2b-b3a203d0865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from PostgreSQL tables into PySpark DataFrames\n",
    "source = [\"tracks\", \"courses\", \"topics\", \"lessons\", \"user_progress_logs\", \"user_feedbacks\"]\n",
    "dfs = {}\n",
    "\n",
    "for table_name in source:\n",
    "    dfs[table_name] = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", postgres_url) \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"user\", properties[\"user\"]) \\\n",
    "        .option(\"password\", properties[\"password\"]) \\\n",
    "        .option(\"driver\", properties[\"driver\"]) \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "937c292e-4ecb-4659-8237-3a84ebee7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidating data with joins\n",
    "transformed_df = (dfs[\"tracks\"].alias(\"tr\")\n",
    "    .join(dfs[\"courses\"].alias(\"c\"), col(\"tr.track_id\") == col(\"c.track_id\"), \"full\")\n",
    "    .join(dfs[\"topics\"].alias(\"tp\"), col(\"c.course_id\") == col(\"tp.course_id\"), \"full\")\n",
    "    .join(dfs[\"lessons\"].alias(\"l\"), col(\"tp.topic_id\") == col(\"l.topic_id\"), \"full\")\n",
    "    .join(dfs[\"user_progress_logs\"].alias(\"upl\"), col(\"l.lesson_id\") == col(\"upl.lesson_id\"), \"full\")\n",
    "    .join(user_registrations_parsed.alias(\"urp\"), col(\"upl.user_id\") == col(\"urp.user_id\"), \"full\")\n",
    "    .join(dfs[\"user_feedbacks\"].alias(\"uf\"), (col(\"urp.user_id\") == col(\"uf.user_id\")) & (col(\"l.lesson_id\") == col(\"uf.lesson_id\")), \"full\")\n",
    "    .select(\n",
    "        col(\"urp.user_id\"),\n",
    "        col(\"urp.registration_date\"),\n",
    "        col(\"l.lesson_title\"),\n",
    "        col(\"l.lesson_type\"),\n",
    "        col(\"l.duration_in_sec\"),\n",
    "        col(\"tp.topic_title\"),\n",
    "        col(\"c.course_title\"),\n",
    "        col(\"tr.track_title\"),\n",
    "        col(\"upl.overall_completion_percentage\"),\n",
    "        col(\"upl.activity_recorded_on\"),\n",
    "        col(\"uf.indicator\"),\n",
    "        col(\"uf.response\"),\n",
    "        col(\"urp.city\"),\n",
    "        col(\"urp.highest_degree\"),\n",
    "        col(\"urp.cgpa\"),\n",
    "        col(\"urp.gender\"),\n",
    "        col(\"urp.dob\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "648136a4-780b-4e00-b42a-e88588226e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new HDFS base path\n",
    "hdfs_path = \"hdfs://localhost:9820/edtech/\"\n",
    "\n",
    "# Generate file name with the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f\"transformed_data_{current_date}.parquet\"\n",
    "\n",
    "#Full hdfs path\n",
    "full_hdfs_path = f\"{hdfs_path}/{file_name}\"\n",
    "\n",
    "# Write DataFrame to Parquet File in the new HDFS path\n",
    "transformed_df.write.mode(\"overwrite\").parquet(full_hdfs_path)\n",
    "\n",
    "# Create a temporary view named \"temp_table\"\n",
    "loaded_df = spark.read.parquet(full_hdfs_path)\n",
    "loaded_df.createOrReplaceTempView(\"temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "455e76a0-9f09-495d-b4da-83cc08808352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hive Target Load for loading transformed data\n",
    "hive_database = 'db_edtech'\n",
    "hive_table_01 = 'edtech_analysis_01'\n",
    "hive_table_02 = 'edtech_analysis_02'\n",
    "\n",
    "# Creating Target Load\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {hive_database}\")\n",
    "spark.sql(f\"USE {hive_database}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8956e0-0dfa-448e-a285-07dca0310ac5",
   "metadata": {},
   "source": [
    "#### Analysis based on Users\n",
    "How do completion rates differ among users based on their highest degree? Is there a significant difference in completion percentages for users with different degrees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c05a1518-9f12-42d0-b8f4-d33cb9ff41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------------------------+\n",
      "|user_count|highest_degree|avg_completion_percentage|\n",
      "+----------+--------------+-------------------------+\n",
      "|       161|          10th|        52.84516129032258|\n",
      "|        78|        B.Tech|        51.76712328767123|\n",
      "|        62|         Inter|                    49.52|\n",
      "|        62|        Degree|        48.60655737704918|\n",
      "|         5|          Ph.d|                     NULL|\n",
      "+----------+--------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis01 = spark.sql(f\"\"\"\n",
    "SELECT \n",
    "count(user_id) as user_count, highest_degree, AVG(overall_completion_percentage) AS avg_completion_percentage\n",
    "FROM temp_table\n",
    "WHERE highest_degree IS NOT NULL\n",
    "GROUP BY highest_degree\n",
    "ORDER BY avg_completion_percentage DESC\n",
    "\"\"\")\n",
    "\n",
    "# Save the analysis results into a Hive table\n",
    "analysis01.write.mode(\"overwrite\").saveAsTable(hive_table_01)\n",
    "\n",
    "# Show the results\n",
    "spark.sql(f\"SELECT * FROM {hive_table_01}\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15556395-a86b-450b-b7f8-84db163d6906",
   "metadata": {},
   "source": [
    "#### Analysis based on Lessons and Courses\n",
    "How does the average lesson duration impact the overall completion percentage across different topics and courses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "877a2e57-8036-4b5d-bc53-aed15a462c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-------------------------+\n",
      "|         topic_title|        course_title|avg_lesson_duration|avg_completion_percentage|\n",
      "+--------------------+--------------------+-------------------+-------------------------+\n",
      "|           Jobby App|    Practical Python|               NULL|                     NULL|\n",
      "|Prototypes and Cl...|JavaScript Essent...|               NULL|                     NULL|\n",
      "|Collaborating wit...|Developer Foundat...|  2914.285714285714|        49.47142857142857|\n",
      "|Third Party Packages|    Practical Python|  3080.769230769231|       50.705882352941174|\n",
      "|Working with Comm...|Developer Foundat...| 3208.1632653061224|        53.89795918367347|\n",
      "| Binary Search Trees|     Data Structures|           3271.875|                53.765625|\n",
      "|Priority Queues &...|     Data Structures|             3600.0|                     63.4|\n",
      "|                NULL|                NULL|             3600.0|                     61.7|\n",
      "|Introduction to A...|Elementary Data S...|             3600.0|        49.13793103448276|\n",
      "|    Numpy and Pandas|    Practical Python|             3900.0|                     39.0|\n",
      "|  Sorting Algorithms|Elementary Data S...| 3983.3333333333335|       44.361111111111114|\n",
      "+--------------------+--------------------+-------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis02 = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "topic_title,\n",
    "course_title,\n",
    "AVG(duration_in_sec) AS avg_lesson_duration,\n",
    "AVG(overall_completion_percentage) AS avg_completion_percentage\n",
    "FROM temp_table\n",
    "GROUP BY topic_title, course_title\n",
    "ORDER BY avg_lesson_duration, avg_completion_percentage DESC;\n",
    "\"\"\")\n",
    "\n",
    "# Save the analysis results into a Hive table\n",
    "analysis02.write.mode(\"overwrite\").saveAsTable(hive_table_02)\n",
    "\n",
    "# Show the results\n",
    "spark.sql(f\"SELECT * FROM {hive_table_02}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66440332-76ed-415e-aaf1-cf94376b9cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hive database 'db_edtech' does not exist or an error occurred.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Clean up data\n",
    "    spark.sql(f\"DROP DATABASE IF EXISTS {hive_database} CASCADE\")\n",
    "\n",
    "    # Try to switch to Hive database\n",
    "    spark.sql(f\"USE {hive_database}\")\n",
    "\n",
    "    # If the database exists, execute SHOW TABLES\n",
    "    spark.sql(f\"SHOW TABLES IN {hive_database}\").show()\n",
    "\n",
    "except Exception as e:\n",
    "    # Catch the exception if the database does not exist\n",
    "    #print(f\"Error: {e}\")\n",
    "    print(f\"The Hive database '{hive_database}' does not exist or an error occurred.\")\n",
    "\n",
    "finally:\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0f735-f4fe-4bce-96a3-d94f1029d7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
